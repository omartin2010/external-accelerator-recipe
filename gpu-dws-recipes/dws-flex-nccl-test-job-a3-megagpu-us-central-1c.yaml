# Copyright 2025 "Google LLC"
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# apiVersion: v1
# kind: Service
# metadata:
#   name: headless-svc-c
# spec:
#   clusterIP: None 
#   selector:
#     job-name: oli-dws-job-zone-c
---
apiVersion: batch/v1
kind: Job
metadata:
  name: oli-dws-job-zone-c
  labels:
    kueue.x-k8s.io/queue-name: dws-local-queue #### DWS
  annotations:
    provreq.kueue.x-k8s.io/maxRunDurationSeconds: "3600"  #### DWS
spec:
  parallelism: 2
  completions: 2
  backoffLimit: 0                       # moved by Olivier
  completionMode: Indexed
  template:
    metadata:        # POD Template - so annotations for pods go here
      annotations:
        devices.gke.io/container.tcpxo-daemon: |+
          - path: /dev/nvidia0
          - path: /dev/nvidia1
          - path: /dev/nvidia2
          - path: /dev/nvidia3
          - path: /dev/nvidia4
          - path: /dev/nvidia5
          - path: /dev/nvidia6
          - path: /dev/nvidia7
          - path: /dev/nvidiactl
          - path: /dev/nvidia-uvm
          - path: /dev/dmabuf_import_helper
        networking.gke.io/default-interface: 'eth0'
        networking.gke.io/interfaces: |
          [
            {"interfaceName":"eth0","network":"default"},
            {"interfaceName":"eth1","network":"gvnic-1"},
            {"interfaceName":"eth2","network":"gvnic-2"},
            {"interfaceName":"eth3","network":"gvnic-3"},
            {"interfaceName":"eth4","network":"gvnic-4"},
            {"interfaceName":"eth5","network":"gvnic-5"},
            {"interfaceName":"eth6","network":"gvnic-6"},
            {"interfaceName":"eth7","network":"gvnic-7"},
            {"interfaceName":"eth8","network":"gvnic-8"}
          ]
    spec:
      hostname: host-c
      tolerations:                      #### DWS
      - key: "nvidia.com/gpu"           #### DWS
        operator: "Exists"              #### DWS
        effect: "NoSchedule"            #### DWS
      nodeSelector:
        cloud.google.com/gke-nodepool: a3-megagpu-8g-a3megagpupool
      subdomain: nccl-domain
      containers:
      - name: nccl-test         # the main workload
        image: us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpxo/nccl-plugin-gpudirecttcpx-dev:v1.0.8-1
        imagePullPolicy: Always
        command:
        - /bin/sh
        - -c
        - |
          set -ex
          chmod 755  /scripts/demo-run-nccl-test-tcpxo-via-mpi.sh
          cat >/scripts/allgather.sh <<EOF
          #!/bin/bash
          /scripts/init_ssh.sh \${@};
          pushd /scripts;
          /scripts/gen_hostfiles.sh \${@};
          popd;
          BENCHMARK=all_gather_perf NHOSTS=2 NCCL_LIB_DIR="${LD_LIBRARY_PATH}" LD_LIBRARY_PATH="${LD_LIBRARY_PATH}" /scripts/demo-run-nccl-test-tcpxo-via-mpi.sh
          EOF
          chmod +x /scripts/allgather.sh
          service ssh restart;
          sleep infinity;
        env:
        - name: LD_LIBRARY_PATH
          value: /usr/local/nvidia/lib64
        - name: NCCL_FASTRAK_LLCM_DEVICE_DIRECTORY
          value: /dev/aperture_devices
        volumeMounts:
        - name: libraries
          mountPath: /usr/local/nvidia
        - name: shared-memory
          mountPath: /dev/shm
        - name: aperture-devices
          mountPath: /dev/aperture_devices
        resources:
          limits:
            nvidia.com/gpu: 8
      - name: tcpxo-daemon
        image: us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpxo/tcpgpudmarxd-dev:v1.0.14
        imagePullPolicy: Always
        command: ["/bin/sh", "-c"]
        args:
          - |
            set -ex
            chmod 755 /fts/entrypoint_rxdm_container.sh
            /fts/entrypoint_rxdm_container.sh --num_hops=2 --num_nics=8 --uid= --alsologtostderr
        securityContext:
          capabilities:
            add:
              - NET_ADMIN
              - NET_BIND_SERVICE
        volumeMounts:
          - name: libraries
            mountPath: /usr/local/nvidia
          - name: sys
            mountPath: /hostsysfs
          - name: proc-sys
            mountPath: /hostprocsysfs
        env:
          - name: LD_LIBRARY_PATH
            value: /usr/local/nvidia/lib64
      volumes:
      - name: shared-memory
        emptyDir:
          medium: "Memory"
          sizeLimit: 1Gi
      - name: libraries
        hostPath:
          path: /home/kubernetes/bin/nvidia
      - name: sys
        hostPath:
          path: /sys
      - name: proc-sys
        hostPath:
          path: /proc/sys
      - name: aperture-devices
        hostPath:
          path: /dev/aperture_devices
      restartPolicy: Never
